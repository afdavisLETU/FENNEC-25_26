{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec375aa9",
   "metadata": {},
   "source": [
    "### fennec-ml Example  \n",
    "This example demonstrates the use of the data utilites in the fennec-ml library\n",
    "\n",
    "#### Setup\n",
    ">1. Make sure data_utils_example.ipynb (this file) is in its own folder. This example program will create all other files and folders it needs \n",
    ">2. Install fennec-ml with:  \n",
    "```pip install fennec-ml```  \n",
    "fennec-ml will install all other dependencies needed\n",
    "\n",
    "\n",
    ">>NOTE: If you have already installed fennec-ml, you need to make sure your library is up to date so use  \n",
    "```pip install --upgrade fennec-ml```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474b0f3",
   "metadata": {},
   "source": [
    "#### **Make example files**  \n",
    "\n",
    "##### YOU DON'T NEED TO UNDERSTAND THE FOLLOWING CODE, IT JUST DOES THE FOLLOWING SETUP\n",
    "\n",
    "**Create excel files** <br>\n",
    "The following code will make 5 example Excel files named according to the 2024-2025 naming convention. A file will be made for each CG category: AA, BB, CC, DD, and EE. <br>\n",
    ">- Each of the five Excel files contains a single worksheet named \"sheet 1\". The worksheet has five columns labeled \"col 1\", \"col 2\", \"col 3\", \"col 4\", and \"col 5\", and contains 100 rows. <br>\n",
    ">- Every cell in a worksheet contains the same number, which is specific to that file: the file with label AA contains only 1s, BB contains only 2s, CC contains only 3s, DD contains only 4s, and EE contains only 5s. <br>\n",
    ">- **Please go look at them if you need to**\n",
    "\n",
    "The Excel files will be stored in ```testing_data\\raw_data``` <br><br>\n",
    "**Create Vars of Interest**<br>\n",
    "A ```vars_of_interest.json``` file will be created in the main folder containing the following json: <br>\n",
    ">{<br>\"sheet 1\": [\"col 1\", \"col 2\", \"col 3\", \"col 4\", \"col 5\"]<br>} <br>\n",
    "- This will direct data_cleaner() to return every column in sheet 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5790dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: clip123B45_AA_L_0.xlsx\n",
      "Created: clip123B45_BB_L_0.xlsx\n",
      "Created: clip123B45_CC_L_0.xlsx\n",
      "Created: clip123B45_DD_L_0.xlsx\n",
      "Created: clip123B45_EE_L_0.xlsx\n",
      "Created /Users/willsstoddard/Documents/Development/Python/FENNEC/FENNEC-25_26/vars_of_interest.json\n"
     ]
    }
   ],
   "source": [
    "# import libraries to make example files\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- FOLDER CONFIG ---\n",
    "data_dir = os.path.join(os.getcwd(), \"testing_data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "excel_dir = os.path.join(data_dir, \"raw_data\")\n",
    "os.makedirs(excel_dir, exist_ok=True)\n",
    "csv_dir = os.path.join(data_dir, \"proccessed_data\")\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(excel_dir, exist_ok=True)\n",
    "\n",
    "# Clear the folder if files already exist\n",
    "for f in os.listdir(excel_dir):\n",
    "    file_path = os.path.join(excel_dir, f)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "# Map labels to numbers\n",
    "label_map = {\n",
    "    \"AA\": 1,\n",
    "    \"BB\": 2,\n",
    "    \"CC\": 3,\n",
    "    \"DD\": 4,\n",
    "    \"EE\": 5\n",
    "}\n",
    "\n",
    "# Generate the Excel files\n",
    "for label, num in label_map.items():\n",
    "    # Create the data: 100 rows Ã— 5 columns filled with the same number\n",
    "    data = np.full((100, 5), num)\n",
    "    df = pd.DataFrame(data, columns=[f\"col {i+1}\" for i in range(5)])\n",
    "\n",
    "    # Filename matching your pattern\n",
    "    filename = f\"clip{123}B{45}_{label}_L_{0}.xlsx\"\n",
    "    filepath = os.path.join(excel_dir, filename)\n",
    "\n",
    "    # Save to Excel with a single sheet called \"sheet 1\"\n",
    "    df.to_excel(filepath, sheet_name=\"sheet 1\", index=False)\n",
    "\n",
    "    print(f\"Created: {filename}\")\n",
    "\n",
    "# --- MAKE VARS OF INTEREST ---\n",
    "base_dir = os.getcwd()\n",
    "json_path = os.path.join(base_dir, \"vars_of_interest.json\")\n",
    "\n",
    "# Data to write\n",
    "vars_of_interest = {\n",
    "    \"sheet 1\": [\"col 1\", \"col 2\", \"col 3\", \"col 4\", \"col 5\"]\n",
    "}\n",
    "\n",
    "# Write to JSON file\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(vars_of_interest, f, indent=4)\n",
    "\n",
    "print(f\"Created {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d514d0",
   "metadata": {},
   "source": [
    "#### Using fennec-ml <br>\n",
    "We will use fennec-ml to proccess the data created above by converting .xlsx to .csv's, scaling the .csv's, extracting the charictarization labels, and segmenting the final data into training, validation, and testing sets<br><br>\n",
    "**Output**\n",
    ">The final result of our work will be a dictionary with 3 keys: *Training_Set*, *Validation_Set*, and *Testing_Set*\n",
    ">>The value of each set is a dict with the follwing keys: *sets* and *labels* <br>\n",
    ">>- *sets* : list of sets\n",
    ">>- *labels* : list of labels<br>\n",
    "\n",
    "Usage ex: \n",
    "```python\n",
    "data_dictionary['Training_Set']['sets']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d95a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using folder_cleaner() to convert from raw excel files to useful .csv's.\n",
      "folder_cleaner() output:\n",
      "clip123B45_BB_L_0.xlsx processed and saved to /Users/willsstoddard/Documents/Development/Python/FENNEC/FENNEC-25_26/testing_data/proccessed_data as clip123B45_BB_L_0.csv\n",
      "clip123B45_EE_L_0.xlsx processed and saved to /Users/willsstoddard/Documents/Development/Python/FENNEC/FENNEC-25_26/testing_data/proccessed_data as clip123B45_EE_L_0.csv\n",
      "clip123B45_AA_L_0.xlsx processed and saved to /Users/willsstoddard/Documents/Development/Python/FENNEC/FENNEC-25_26/testing_data/proccessed_data as clip123B45_AA_L_0.csv\n",
      "clip123B45_CC_L_0.xlsx processed and saved to /Users/willsstoddard/Documents/Development/Python/FENNEC/FENNEC-25_26/testing_data/proccessed_data as clip123B45_CC_L_0.csv\n",
      "clip123B45_DD_L_0.xlsx processed and saved to /Users/willsstoddard/Documents/Development/Python/FENNEC/FENNEC-25_26/testing_data/proccessed_data as clip123B45_DD_L_0.csv\n",
      "\n",
      "Using segment_and_split() to cut data into training/validtion/testing sets\n",
      "segment_and_split() output:\n",
      "All data segmented and sorted!\n",
      "Training_Sets: 35\n",
      "Validation_Sets: 7\n",
      "Testing_Sets: 8\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORT FENNEC-ML --- \n",
    "import fennec_ml as fn # note the underscore\n",
    "\n",
    "# --- EXCEL TO CSV ---\n",
    "print(\"Using folder_cleaner() to convert from raw excel files to useful .csv's.\\nfolder_cleaner() output:\")\n",
    "fn.folder_cleaner(excel_dir, csv_dir, overwrite= True)\n",
    "\n",
    "# --- SCALING AND LABELS ---\n",
    "scaled_data = fn.standardize(csv_dir)\n",
    "# scaled_data = fn.normalize(csv_dir)\n",
    "labels = fn.get_1D_CG_labels(csv_dir)\n",
    "\n",
    "# --- SEGMENTING AND SPLITTING ---\n",
    "print(\"\\nUsing segment_and_split() to cut data into training/validtion/testing sets\\nsegment_and_split() output:\")\n",
    "# using default 70%/15%/15% train/val/test split\n",
    "dataset_dict = fn.segment_and_split(scaled_data, labels, timesteps = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d80ebe",
   "metadata": {},
   "source": [
    "#### Verify Results  \n",
    "To verify the results, the below code will print out the correct value stored in each type of dataset.\n",
    "\n",
    "It will then print out the first 5 labels in the Training_Set and the corresponding datasets for you to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a463af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Key:\n",
      "AA corresponds to -1.414213562373095\n",
      "BB corresponds to -0.7071067811865475\n",
      "CC corresponds to 0.0\n",
      "DD corresponds to 0.7071067811865475\n",
      "EE corresponds to 1.414213562373095\n",
      "\n",
      "First 5 training sets\n",
      "\n",
      "Training_Set Label: CC\n",
      "Training_Set Dataset: \n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "Training_Set Label: DD\n",
      "Training_Set Dataset: \n",
      "[[0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]]\n",
      "\n",
      "Training_Set Label: DD\n",
      "Training_Set Dataset: \n",
      "[[0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]\n",
      " [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678]]\n",
      "\n",
      "Training_Set Label: EE\n",
      "Training_Set Dataset: \n",
      "[[1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      " [1.41421356 1.41421356 1.41421356 1.41421356 1.41421356]]\n",
      "\n",
      "Training_Set Label: CC\n",
      "Training_Set Dataset: \n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Verification\n",
    "print(\"Classification Key:\")\n",
    "for i in range(len(labels)):\n",
    "    print(f\"{labels[i]} corresponds to {scaled_data[i][1][1]}\")\n",
    "\n",
    "print(\"\\nFirst 5 training sets\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nTraining_Set Label: {(dataset_dict['Training_Set']['labels'][i])}\")\n",
    "    print(f\"Training_Set Dataset: \\n{(dataset_dict['Training_Set']['sets'][i])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fennecvenv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
